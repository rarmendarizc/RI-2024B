{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Taller 07\n",
        "\n",
        "Nombre: Rossy Armendariz\n",
        "\n",
        "Contar con la funcion wc las palabras de cada episodio."
      ],
      "metadata": {
        "id": "_46dAm8BTC9G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oVQuLJcPl4L",
        "outputId": "ed5d89f0-73b6-4722-a0f1-34d1c1ac251d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text     wc\n",
            "0  As part of MIT course 6S099, Artificial Genera...  13424\n",
            "1  As part of MIT course 6S099 on artificial gene...  10217\n",
            "2  You've studied the human mind, cognition, lang...   5989\n",
            "3  What difference between biological neural netw...   5993\n",
            "4  The following is a conversation with Vladimir ...   6374\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "file_path = '/content/sample_data/podcastdata_dataset.csv'\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "def wc(text):\n",
        "    return len(str(text).split())\n",
        "\n",
        "df['wc'] = df['text'].apply(wc)\n",
        "\n",
        "print(df[['text', 'wc']].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se divide las oraciones de cada episodio y se guarda una nueva data."
      ],
      "metadata": {
        "id": "vf_tiwxrTbv9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ryc25U5UPl4N"
      },
      "outputs": [],
      "source": [
        "new_data = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    ep_id = row['id']\n",
        "    text = row['text']\n",
        "\n",
        "    sentences = sent_tokenize(str(text))\n",
        "\n",
        "    for st_id, sentence in enumerate(sentences, start=1):\n",
        "        new_data.append({'ep_id': ep_id, 'st_id': st_id, 'text': sentence, 'wc': len(sentence.split())})\n",
        "\n",
        "df_split_sentences = pd.DataFrame(new_data)\n",
        "\n",
        "df_split_sentences.to_csv('/content/sample_data/podcastdata_split_sentences.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se realiza un embedding con word2vec."
      ],
      "metadata": {
        "id": "XNTxatHJTgFk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anN7Zey-Pl4N",
        "outputId": "ec66e2cd-e23f-4a39-f3f7-b19b07457fa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ep_id  st_id                                               text  wc  \\\n",
            "0      1      1  As part of MIT course 6S099, Artificial Genera...  19   \n",
            "1      1      2                     He is a professor here at MIT.   7   \n",
            "2      1      3  He's a physicist, spent a large part of his ca...  17   \n",
            "3      1      4  But he's also studied and delved into the bene...  17   \n",
            "4      1      5  Amongst many other things, he is the cofounder...  24   \n",
            "\n",
            "                                           embedding  \n",
            "0  [-0.3031589194821815, -0.44866556622501874, 0....  \n",
            "1  [0.28318262845277786, 0.8343306680520376, -0.6...  \n",
            "2  [0.2361072490612666, 0.5584602177143096, 0.441...  \n",
            "3  [0.05692772003000274, -0.15040886730832212, 0....  \n",
            "4  [-0.16736447098462479, 0.26830030499917007, 0....  \n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "# Paso 1: Preprocesar las oraciones para entrenar Word2Vec\n",
        "sentences_for_w2v = [simple_preprocess(sentence) for sentence in df_split_sentences['text']]\n",
        "\n",
        "# Paso 2: Entrenar el modelo Word2Vec\n",
        "w2v_model = Word2Vec(sentences=sentences_for_w2v, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Paso 3: Crear embeddings para cada oración\n",
        "def calculate_embedding(sentence):\n",
        "    words = simple_preprocess(sentence)\n",
        "    word_vectors = [w2v_model.wv[word] for word in words if word in w2v_model.wv]\n",
        "    if word_vectors:\n",
        "        # Calcular el promedio manualmente sin NumPy\n",
        "        summed_vector = [sum(x) for x in zip(*word_vectors)]\n",
        "        avg_vector = [val / len(word_vectors) for val in summed_vector]\n",
        "        return avg_vector\n",
        "    else:\n",
        "        return [0] * w2v_model.vector_size  # Vector nulo si no hay palabras conocidas\n",
        "\n",
        "# Aplicar la función a cada oración\n",
        "df_split_sentences['embedding'] = df_split_sentences['text'].apply(calculate_embedding)\n",
        "\n",
        "# Guardar el DataFrame con embeddings\n",
        "df_split_sentences.to_csv('/content/sample_data/podcastdata_split_with_wc_word2vec_no_numpy.csv', index=False)\n",
        "\n",
        "# Verificar las primeras filas\n",
        "print(df_split_sentences.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se agrupa los embeddings para tener dividido en cluster de topics."
      ],
      "metadata": {
        "id": "-BEj22f-Tkn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import normalize\n",
        "import gc  # Importar el garbage collector\n",
        "\n",
        "file_path = '/content/sample_data/podcastdata_split_with_wc_word2vec_no_numpy.csv'\n",
        "chunk_size = 1000\n",
        "\n",
        "results = []\n",
        "\n",
        "for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
        "    # Convertir la columna de embeddings a listas de floats\n",
        "    chunk['embedding'] = chunk['embedding'].apply(lambda x: ast.literal_eval(x))\n",
        "\n",
        "    # Normalizar embeddings\n",
        "    embedding_matrix = normalize(chunk['embedding'].tolist())\n",
        "\n",
        "    # Realizar clustering\n",
        "    kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "    chunk['cluster'] = kmeans.fit_predict(embedding_matrix)\n",
        "\n",
        "    results.append(chunk)\n",
        "    del embedding_matrix  # Eliminar embeddings de memoria\n",
        "    gc.collect()  # Forzar la recolección de basura\n",
        "\n",
        "# Combinar todos los chunks\n",
        "df_result = pd.concat(results)\n",
        "\n",
        "# Guardar los resultados en un nuevo archivo\n",
        "df_result.to_csv('/content/sample_data/podcastdata_with_clusters.csv', index=False)\n",
        "\n",
        "print(\"Clustering completado y resultados guardados.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmYPm2ZERwfn",
        "outputId": "e1651e44-2413-4829-d2d3-92d77311f83f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clustering completado y resultados guardados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consulta"
      ],
      "metadata": {
        "id": "fkLEI88FW9FR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "# Define la consulta\n",
        "query = \"What is artificial intelligence and its applications?\"\n",
        "\n",
        "#  Preprocesar la consulta\n",
        "query_words = simple_preprocess(query)\n",
        "\n",
        "#  Generar el embedding de la consulta\n",
        "def generate_query_embedding(words, w2v_model, vector_size=100):\n",
        "    word_vectors = [w2v_model.wv[word] for word in words if word in w2v_model.wv]\n",
        "    if word_vectors:\n",
        "        summed_vector = [sum(x) for x in zip(*word_vectors)]\n",
        "        avg_vector = [val / len(word_vectors) for val in summed_vector]\n",
        "        return avg_vector\n",
        "    else:\n",
        "        return [0] * vector_size  # Vector nulo si no hay palabras conocidas\n",
        "\n",
        "query_embedding = generate_query_embedding(query_words, w2v_model)\n",
        "\n",
        "# Calcular la similitud coseno con todos los embeddings\n",
        "embedding_matrix = df_result['embedding'].tolist()  # Asegúrate de que sea una lista de vectores\n",
        "similarities = cosine_similarity([query_embedding], embedding_matrix)[0]\n",
        "\n",
        "# Ordenar por similitud\n",
        "df_result['similarity'] = similarities\n",
        "top_results = df_result.sort_values(by='similarity', ascending=False).head(10)\n",
        "\n",
        "# Mostrar los resultados más relevantes\n",
        "print(\"Resultados más relevantes para la consulta:\")\n",
        "print(top_results[['text', 'similarity']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPevFT7GenoN",
        "outputId": "26b75f66-e060-4150-a30f-44769f4e76ce"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados más relevantes para la consulta:\n",
            "                                                     text  similarity\n",
            "42468              Like, what is artificial intelligence?    0.864519\n",
            "9660    And so what you see is, is that artificial int...    0.851076\n",
            "291403  Similarly for intelligence, we know the human ...    0.846471\n",
            "75307   That's the goal of artificial intelligence is ...    0.845170\n",
            "379205                What is the origin of intelligence?    0.842657\n",
            "275783               What is optoelectronic intelligence?    0.838374\n",
            "42229   That's what my research is, is artificial inte...    0.838045\n",
            "248396             So what is the origin of intelligence?    0.836947\n",
            "131565                     Is it artificial intelligence?    0.835423\n",
            "133971            It's a form of artificial intelligence.    0.832041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lIbn-7YJTBQr"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}